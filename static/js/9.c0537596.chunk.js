(this["webpackJsonppersonal-site"]=this["webpackJsonppersonal-site"]||[]).push([[9],{161:function(e,a,t){"use strict";t.r(a);var n=t(1),i=t(160),r=(t(0),t(5)),s=t(70),o=t.n(s),l=t(18),c="\n# Intro\n\nI am Yi Zhang, a 6th year Ph.D. student at Uiversity of Pennylvania, advised by Prof. [Zack Ives](https://www.cis.upenn.edu/~zives/) and Prof. [Dan Roth](https://www.cis.upenn.edu/~danroth/). My research interests lie broadly in **natural lanaguge processing** and **data management systems**.\n\n# My Research\n\nDuring my Ph.D. study at Penn, my research is mostly about helping people understand natural lanaguge claims and data analytics-driven reports, by exploring provenance-based contextual information.\n\n- For a natural lanaguge claim, we propose ''*claim provenance*'' to describe where a claim may come from and explain how it may have been derived. We infer it by developing novel *information extraction*, *text generation* and *reasoning* techniques. In particular, we also study how a quantitative claim in natural lanaguge interacts with structure data.\n\n- For a data analytics-driven report with tables or visualizations, we build a search platform over data in a ''data lake'', which finds relevant supplementary (*joinable* or *unionable*) data in an *interactive speed*. Our tool provides additional data as well as provenance information, to help user assess whether data was ''cherry picked'' or representative, and thus whether it supports specific claims or conclusions. Meanwhile, our tool can also recommend data scientists related data analytics pipelines via exploring the relatedness between data generated by different workflows.\n\n- To bridge the two contexts, we explore data provenance for quantitative natural language claims. Typically, quantitative claims are compositional queries with discrete computations on specific tables, while the claim may not explicitly specify which operators, columns or rows are involved in the computation. Therefore, it is difficult to match the claims to the tables directly. Instead, I propose to generate *latent programs* for a given quantitative claim and reason potential alignments between the generated variables in the latent program to the columns and rows in candidate tables to better support the search for the right source tables.\n\n# I like\n\n- Boxing\n- Karate\n- Tennis\n- Swimming\n- ...\n\n# I dream of\n\n- always finding inspiration.\n",d=c.split(/\s+/).map((function(e){return e.replace(/\W/g,"")})).filter((function(e){return e.length})).length,u=function(e){var a=Object.assign({},e);return Object(n.jsx)(r.b,Object(i.a)({},a))};a.default=function(){return Object(n.jsx)(l.a,{title:"About",description:"Learn about Yi Zhang",children:Object(n.jsxs)("article",{className:"post markdown",id:"about",children:[Object(n.jsx)("header",{children:Object(n.jsxs)("div",{className:"title",children:[Object(n.jsx)("h2",{"data-testid":"heading",children:Object(n.jsx)(r.b,{to:"/about",children:"About Me"})}),Object(n.jsxs)("p",{children:["(in about ",d," words)"]})]})}),Object(n.jsx)(o.a,{source:c,renderers:{Link:u},escapeHtml:!1})]})})}}}]);
//# sourceMappingURL=9.c0537596.chunk.js.map